{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Time Series - Maker workshop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Quick round table\n",
    "\n",
    "Presentation & expectations?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition\n",
    "\n",
    "- **Time series data is data that is collected at different points in time.** This is opposed to cross-sectional data which observes individuals, companies, etc. at a single point in time.\n",
    "\n",
    "\n",
    "- If you previously followed the *Maker workshop dedicated to Machine Learning*, you've already worked with cross-sectional data, but not time series.\n",
    "\n",
    "\n",
    "- Time series can be found in a wide variety of domains: in economics, social sciences, medicine, but also ( and obviously) in physical sciences and engineering. As a result, **we deal with them a lot at Total!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Outline\n",
    "\n",
    "1. Today's challenge\n",
    "2. Today's Data Science environment checklist\n",
    "3. Exploring the data \n",
    "    - Types, indexes and unique values\n",
    "    - Distributions\n",
    "    - Correlations\n",
    "4. Dealing with missing values\n",
    "5. Resampling techniques\n",
    "6. Time series visualization\n",
    "7. Anomalies detection techniques\n",
    "8. Forecasting\n",
    "8. Open discussion / work session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Today's Challenge\n",
    "\n",
    "**Predict the air temperature in 2017 based on weather data from 2009 to 2016.**\n",
    "\n",
    "- Features available:\n",
    "    - Air temperature\n",
    "    - Atmospheric pressure\n",
    "    - Humidity\n",
    "    - Wind direction\n",
    "    - Etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Today's Data Science environment checklist\n",
    "\n",
    "- A Jupyter notebook\n",
    "- The data folder (the one that we sent)\n",
    "- The following libraries installed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "! make -f ../setup/Makefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from fbprophet import Prophet\n",
    "\n",
    "# Optional\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data = pd.read_csv('../data/jena_climate_2009_2016_part_3.csv')\n",
    "clean_data.set_index('Date Time', inplace=True)\n",
    "clean_data.index = pd.to_datetime(clean_data.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Anomalies detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "- An anomaly is an outlier data point, which does not follow the collective common pattern of the majority of the data points and hence can be easily separated or distinguished from the rest of the data.\n",
    "\n",
    "- In our case, we can try to identify abnormal temperatures over the period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Fix threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "TAG_NAME = 'T (degC)'\n",
    "\n",
    "plt.figure(figsize=(20, 7))\n",
    "\n",
    "clean_data[TAG_NAME].plot()\n",
    "plt.title(TAG_NAME)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "_What could be a relevant threshold to apply to this specific sensor ?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Now, consider that we apply the following thresholds (upper/lower) for the specified sensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "SENSORS_THRESHOLDS = {TAG_NAME:[-15, 34]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's backtest our **fix threshold** strategy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backtesting_df = clean_data.copy()\n",
    "\n",
    "for col in SENSORS_THRESHOLDS.keys():\n",
    "    upper_alert = (backtesting_df[col] > SENSORS_THRESHOLDS[col][1])\n",
    "    lower_alert = (backtesting_df[col] < SENSORS_THRESHOLDS[col][0])\n",
    "    \n",
    "    backtesting_df[f'is_alert_{col}'] = (upper_alert | lower_alert).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 7))\n",
    "\n",
    "backtesting_df[f'is_alert_{TAG_NAME}'].plot(color='red')\n",
    "plt.title(f'Fix threshold - Alerting state on sensor {TAG_NAME}')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Statistical profiling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Creating a statistical profile of the data can be the fastest and the most useful approach, and it still offers a **clear and explainable outcome**.\n",
    "\n",
    "- In the case of statistical profiling, **we use the mean, median, standard deviations and/or quantiles to come up with upper and lower bounds** to detect anomalies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 5))\n",
    "\n",
    "sns.boxplot(clean_data[TAG_NAME])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Now, consider that we use the 1st and 99th quantiles for the specified sensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUANTILE_PARAM = 0.99\n",
    "\n",
    "upper_quantile = clean_data[TAG_NAME].\"CODE HERE\"(QUANTILE_PARAM)\n",
    "lower_quantile = clean_data[TAG_NAME].\"CODE HERE\"(1-QUANTILE_PARAM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's backtest our **statistical profiling** strategy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backtesting_df = clean_data.copy()\n",
    "\n",
    "for col in SENSORS_THRESHOLDS.keys():\n",
    "    upper_alert = (backtesting_df[col] > upper_quantile)\n",
    "    lower_alert = (backtesting_df[col] < lower_quantile)\n",
    "    \n",
    "    backtesting_df[f'is_alert_{col}'] = (upper_alert | lower_alert).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 7))\n",
    "\n",
    "backtesting_df[f'is_alert_{TAG_NAME}'].plot(color='red')\n",
    "plt.title(f'Statistical profiling - Alerting state on sensor {TAG_NAME}')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### A word of caution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "One needs to be careful when predicting the future:\n",
    "\n",
    "- _\"Stocks have reached what looks like a permanently high plateau.\"_ - Irving Fischer, Professor of Economics, Yale University, 1929\n",
    "    - True or False?\n",
    "\n",
    "- _\"Computers in the future weigh no more than 1.5 tons.\"_ - Popular Mechanics, forecasting the relentless march of science, 1949\n",
    "    - True or False?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Introduction to Prophet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "- Open-sourced by Facebook's core data science team a few years ago, Prophet is based on time series decomposition but has the ability to model different seasonalities as well as the effect of holidays and special events.\n",
    "\n",
    "- On [Prophet Github page](https://github.com/facebook/prophet), we find the following description:\n",
    "\n",
    "_\"Prophet is a procedure for forecasting time series data based on an additive model where non-linear trends are fit with yearly, weekly, and daily seasonality, plus holiday effects. It works best with time series that have strong seasonal effects and several seasons of historical data. Prophet is robust to missing data and shifts in the trend, and typically handles outliers well.\"_\n",
    "\n",
    "- In this section, we'll try to assess how Prophet performs to predict the future value of the temperature (the T (degC) sensor)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The input to Prophet is always a DataFrame with 2 columns: `ds` and `y`:\n",
    "- The `ds` (datestamp) column should be of a format expected by pandas, ideally YYYY-MM-DD for a date or YYYY-MM-DD HH:MM:SS for a timestamp. \n",
    "- The `y` column must be numeric, and represents the measurement we wish to forecast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "TAG_NAME = 'T (degC)'\n",
    "\n",
    "prophet_df = clean_data.\"CODE HERE\"('1d').\"CODE HERE\"()\n",
    "prophet_df = prophet_df[[TAG_NAME]].reset_index()\n",
    "prophet_df = prophet_df.rename(columns={'Date Time':'ds', TAG_NAME:'y'})\n",
    "\n",
    "prophet_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Prophet follows the sklearn model API. We create an instance of the `Prophet `class and then call its `fit` and `predict` methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "model = Prophet()\n",
    "model.fit(prophet_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Now that we have a model, we can make predictions on a DataFrame with a column `ds` containing the dates for which a prediction is to be made. \n",
    "\n",
    "You can get a suitable DataFrame that extends into the future a specified number of days using the helper method `Prophet.make_future_dataframe` (by default, it will also include the dates from the history)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "future = model.make_future_dataframe(periods=365)\n",
    "future.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Now, we can apply the `predict` method to this DataFrame: it will assign each row a predicted value which it names `yhat`. If you pass in historical dates, it will provide an in-sample fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast = model.\"CODE HERE\"(future)\n",
    "forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We can plot the forecast by calling the `Prophet.plot` method and passing in our forecast DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "fig1 = model.\"CODE HERE\"(forecast)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "If you want to see the forecast components, you can use the `Prophet.plot_components` method. \n",
    "\n",
    "By default you’ll see the trend, yearly seasonality, and weekly seasonality of the time series. If you include holidays, you’ll see those here, too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig2 = model.\"CODE HERE\"(forecast)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Thank you!\n",
    "### Any feedback? Return on time invested?"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "336px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
